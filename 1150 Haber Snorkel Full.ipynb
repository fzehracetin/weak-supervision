{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Haber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>bi̇z daha ölmedi̇k\"   galatasaray, levski sofy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>nihat’ın zor sınavı       i̇spanya ligi’nde li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>avea: şartlar gelişirse telsim'i mutlaka değer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vagon fabrikası jean üretim merkezi oluyor   t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>kırık tedavisinde yeni metot   yüzüncü yıl üni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>milli güvenlik kurulu genel sekreterliği’nde d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>kenan doğulu, 'metroseksüel' benzetmesinden ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>erdoğan, kız yurdunda yemek yedi              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>doğru yol’un ‘telefon sapığı’   dsp milletveki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>ralf ile derin'in nişantaşı molası   ender mer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>elektron mikroskobuyla, hücre dilimlerinin ayr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>çiçek’ten bakana: hepimiz aleviyiz        devl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>plastikten, kablolardan ve bilgisayar devreler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>hilton otelleri vârisi evlendi    hilton otell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>cilt kanseri teşhisinde teknolojik gelişme   d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>garanti bankası'nın hissedarı doğuş inşaat ve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>göz cerrahisinde devrim yaratacak olan proje, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>transfere bi̇r çare   sezon başında kesinleşmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>kaçak ve usulsüz doğalgaz kullananlardan, hesa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>cumhurbaşkanı ahmet necdet sezer, i̇sveç’in an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Haber\n",
       "210  bi̇z daha ölmedi̇k\"   galatasaray, levski sofy...\n",
       "188  nihat’ın zor sınavı       i̇spanya ligi’nde li...\n",
       "249  avea: şartlar gelişirse telsim'i mutlaka değer...\n",
       "7    vagon fabrikası jean üretim merkezi oluyor   t...\n",
       "580  kırık tedavisinde yeni metot   yüzüncü yıl üni...\n",
       "850  milli güvenlik kurulu genel sekreterliği’nde d...\n",
       "294  kenan doğulu, 'metroseksüel' benzetmesinden ra...\n",
       "381  erdoğan, kız yurdunda yemek yedi              ...\n",
       "85   doğru yol’un ‘telefon sapığı’   dsp milletveki...\n",
       "316  ralf ile derin'in nişantaşı molası   ender mer...\n",
       "291  elektron mikroskobuyla, hücre dilimlerinin ayr...\n",
       "756  çiçek’ten bakana: hepimiz aleviyiz        devl...\n",
       "556  plastikten, kablolardan ve bilgisayar devreler...\n",
       "279  hilton otelleri vârisi evlendi    hilton otell...\n",
       "303  cilt kanseri teşhisinde teknolojik gelişme   d...\n",
       "395  garanti bankası'nın hissedarı doğuş inşaat ve ...\n",
       "864  göz cerrahisinde devrim yaratacak olan proje, ...\n",
       "200  transfere bi̇r çare   sezon başında kesinleşmi...\n",
       "267  kaçak ve usulsüz doğalgaz kullananlardan, hesa...\n",
       "859  cumhurbaşkanı ahmet necdet sezer, i̇sveç’in an..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "news = []\n",
    "\n",
    "for directory in os.listdir(\"1150haber/raw_texts/\"):\n",
    "    for filename in os.listdir(\"1150haber/raw_texts/\" + directory):\n",
    "        f = open(\"1150haber/raw_texts/\" + directory + \"/\" + filename, \"r\", encoding=\"windows-1254\")\n",
    "        new = f.read().replace(\"\\n\", \" \")\n",
    "        new = new.lower()\n",
    "        news.append(new)\n",
    "        \n",
    "random.shuffle(news)\n",
    "print(len(news))\n",
    "\n",
    "data = {\"Haber\": news}\n",
    "df_train = pd.DataFrame(data)\n",
    "df_train[\"Haber\"] = df_train[\"Haber\"].apply(str)\n",
    "df_train.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Haber</th>\n",
       "      <th>Sınıf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prof. dr. mehmet öz, sağlıklı yaşam için dikka...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nazan öncel coşkusu    sahnelere altı yıl ara ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ankara üniversitesi tıp fakültesi farmakoloji ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[habersağlık-i̇stanbul] mesleğinin baharında, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yıllardır televizyon kanallarına başarılı prog...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>green card’ı çekecekti ‘green card’ını kaybett...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>ssk’ya pahalı ilaç satarak devleti zarara uğra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>ankara - türk telekom'un indirim reklamları sa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>ytl'de sahteyi ayıklama makinasında yarış kızı...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>f tipi, tutuklunun ruh sağlığını bozuyor   i̇n...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Haber  Sınıf\n",
       "0    prof. dr. mehmet öz, sağlıklı yaşam için dikka...      3\n",
       "1    nazan öncel coşkusu    sahnelere altı yıl ara ...      2\n",
       "2    ankara üniversitesi tıp fakültesi farmakoloji ...      3\n",
       "3    [habersağlık-i̇stanbul] mesleğinin baharında, ...      3\n",
       "4    yıllardır televizyon kanallarına başarılı prog...      2\n",
       "..                                                 ...    ...\n",
       "225  green card’ı çekecekti ‘green card’ını kaybett...      2\n",
       "226  ssk’ya pahalı ilaç satarak devleti zarara uğra...      1\n",
       "227  ankara - türk telekom'un indirim reklamları sa...      1\n",
       "228  ytl'de sahteyi ayıklama makinasında yarış kızı...      1\n",
       "229  f tipi, tutuklunun ruh sağlığını bozuyor   i̇n...      3\n",
       "\n",
       "[230 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "news = []\n",
    "labels = []\n",
    "filenames = []\n",
    "i = 0\n",
    "\n",
    "for directory in os.listdir(\"1150haber/test/\"):\n",
    "    i += 1\n",
    "    for filename in os.listdir(\"1150haber/test/\" + directory):\n",
    "        f = open(\"1150haber/test/\" + directory + \"/\" + filename, \"r\", encoding=\"windows-1254\")\n",
    "        new = f.read().replace(\"\\n\", \" \")\n",
    "        new = new.lower()\n",
    "        news.append(new)\n",
    "        labels.append(i)\n",
    "        \n",
    "print(len(news))\n",
    "\n",
    "data = {\"Haber\": news, \"Sınıf\": labels}\n",
    "df_test = pd.DataFrame(data)\n",
    "df_test[\"Haber\"] = df_test[\"Haber\"].apply(str)\n",
    "df_test = df_test.sample(frac = 1).reset_index(drop=True)\n",
    "df_test.sample(230).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background for labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = [\"lira\", \"dolar\", \"döviz\", \"faiz\"]\n",
    "ekonomi_kavramlar = [\"cari\", \"enflasyon\", \"merkez bankası\", \"imf\", \"kredi\", \"yatırım\"]\n",
    "sayi_birimleri = [\"milyon\", \"milyar\", \"bin\", \"trilyon\", \"katrilyon\"]\n",
    "\n",
    "magazin_kavramlar = [\"ünlü\", \"tatil\", \"bodrum\", \"konser\", \"sevgili\", \"yakışıklı\", \"aşk\"]\n",
    "magazin_meslekler = [\"manken\", \"oyuncu\", \"aktör\"]\n",
    "magazin_kisiler = [\"hülya avşar\", \"beren saat\", \"ajda pekkan\", \"demet akalın\", \"mehmet ali erbil\"]\n",
    "\n",
    "vucut_bolumleri = [\"kalp\", \"diş\", \"göz\", \"damar\", \"ağız\", \"cilt\", \"vücut\", \"yağ\", \"böbrek\", \"kan\", \"tırnak\", \"bağırsak\", \"baş\"]\n",
    "saglik_kavramlar = [\"tedavi\", \"bilim\", \"ilaç\", \"teşhis\", \"hasta\", \"tıp\", \"ameliyat\", \"ssk\", \"hastane\"]\n",
    "hastaliklar = [\"kanser\", \"şeker\", \"yağ\", \"hastalık\", \"doğum\", \"anne\", \"görme\", \"tansiyon\"]\n",
    "\n",
    "siyasi_rutbeler = [\"genel başkanı\", \"milletvekili\", \"bakan\", \"başbakan\", \"cumhurbaşkanı\", \"dışişleri\"]\n",
    "siyasi_kavramlar = [\"abd\", \"erdoğan\", \"kılıçdaroğlu\", \"demirtaş\", \"bahçeli\", \"akşener\", \"avrupa\", \"büyükşehir\", \"anayasa\", \"abd\"]\n",
    "siyasi_partiler = [\"akp\", \"chp\", \"mhp\", \"hdp\"]\n",
    "\n",
    "spor_kavramlar = [\"teknik\", \"milli\", \"gol\", \"takım\", \"maç\", \"transfer\", \"forma\", \"uefa\", \"direktör\", \"terim\"]\n",
    "takimlar = [\"fenerbahçe\", \"galatasaray\", \"beşiktaş\", \"trabzonspor\", \"barcelona\", \"arjantin\", \"kocaelispor\"]\n",
    "dallar = [\"futbolcu\", \"kupa\", \"saha\", \"hakem\", \"lig\", \"rakip\", \"şampiyon\", \"deplasman\", \"futbol\", \"basketbol\", \"penaltı\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EKONOMI = 1\n",
    "MAGAZIN = 2\n",
    "SAGLIK = 3\n",
    "SIYASI = 4\n",
    "SPOR = 5\n",
    "BELIRSIZ = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "import re\n",
    "\n",
    "@labeling_function()\n",
    "def para_iceriyor(sample_new):\n",
    "    for para_tipi in para:\n",
    "        if re.search(para_tipi, sample_new.Haber):\n",
    "            return EKONOMI \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def ekonomik_kavram_iceriyor(sample_new):\n",
    "    for ekonomik_kavram in ekonomi_kavramlar:\n",
    "         if re.search(ekonomik_kavram, sample_new.Haber):\n",
    "            return EKONOMI\n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def sayi_birimi_iceriyor(sample_new):\n",
    "    for sayi_birimi in sayi_birimleri:\n",
    "        if re.search(sayi_birimi, sample_new.Haber):\n",
    "            return EKONOMI \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def magazin_kavrami_iceriyor(sample_new):\n",
    "    for magazin_kavrami in magazin_kavramlar:\n",
    "        if re.search(magazin_kavrami, sample_new.Haber):\n",
    "            return MAGAZIN \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def magazin_meslegi_iceriyor(sample_new):\n",
    "    for magazin_meslegi in magazin_meslekler:\n",
    "        if re.search(magazin_meslegi, sample_new.Haber):\n",
    "            return MAGAZIN \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def magazin_kisiler_iceriyor(sample_new):\n",
    "    for magazin_kisisi in magazin_kisiler:\n",
    "        if re.search(magazin_kisisi, sample_new.Haber):\n",
    "            return MAGAZIN \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def vucut_bolumu_iceriyor(sample_new):\n",
    "    for vucut_bolumu in vucut_bolumleri:\n",
    "        if re.search(vucut_bolumu, sample_new.Haber):\n",
    "            return SAGLIK \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def saglik_kavramlari_iceriyor(sample_new):\n",
    "    for saglik_kavrami in saglik_kavramlar:\n",
    "        if re.search(saglik_kavrami, sample_new.Haber):\n",
    "            return SAGLIK\n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def hastalik_iceriyor(sample_new):\n",
    "    for hastalik in hastaliklar:\n",
    "        if re.search(hastalik, sample_new.Haber):\n",
    "            return SAGLIK \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def siyasi_rutbe_iceriyor(sample_new):\n",
    "    for siyasi_rutbe in siyasi_rutbeler:\n",
    "        if re.search(siyasi_rutbe, sample_new.Haber):\n",
    "            return SIYASI \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def siyasi_kavram_iceriyor(sample_new):\n",
    "    for siyasi_kavram in siyasi_kavramlar:\n",
    "        if re.search(siyasi_kavram, sample_new.Haber):\n",
    "            return SIYASI \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def siyasi_parti_iceriyor(sample_new):\n",
    "    for siyasi_parti in siyasi_partiler:\n",
    "        if re.search(siyasi_parti, sample_new.Haber):\n",
    "            return SIYASI \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def spor_kavramlar_iceriyor(sample_new):\n",
    "    for spor_kavrami in spor_kavramlar:\n",
    "        if re.search(spor_kavrami, sample_new.Haber):\n",
    "            return SPOR \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def takimlar_iceriyor(sample_new):\n",
    "    for takim in takimlar:\n",
    "        if re.search(takim, sample_new.Haber):\n",
    "            return SPOR \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def spor_dallari_iceriyor(sample_new):\n",
    "    for spor_dali in dallar:\n",
    "        if re.search(spor_dali, sample_new.Haber):\n",
    "            return SPOR \n",
    "    return BELIRSIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 920/920 [00:04<00:00, 213.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [para_iceriyor, ekonomik_kavram_iceriyor, sayi_birimi_iceriyor, magazin_kavrami_iceriyor, magazin_meslegi_iceriyor, \n",
    "       magazin_kisiler_iceriyor, vucut_bolumu_iceriyor, saglik_kavramlari_iceriyor, hastalik_iceriyor, siyasi_rutbe_iceriyor, \n",
    "       siyasi_kavram_iceriyor, siyasi_parti_iceriyor, spor_kavramlar_iceriyor, takimlar_iceriyor, spor_dallari_iceriyor]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "L_test = applier.apply(df=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>para_iceriyor</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.234783</td>\n",
       "      <td>0.234783</td>\n",
       "      <td>0.230435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ekonomik_kavram_iceriyor</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.122826</td>\n",
       "      <td>0.121739</td>\n",
       "      <td>0.119565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sayi_birimi_iceriyor</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.410870</td>\n",
       "      <td>0.409783</td>\n",
       "      <td>0.405435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magazin_kavrami_iceriyor</th>\n",
       "      <td>3</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.547826</td>\n",
       "      <td>0.538043</td>\n",
       "      <td>0.528261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magazin_meslegi_iceriyor</th>\n",
       "      <td>4</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.178261</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.167391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magazin_kisiler_iceriyor</th>\n",
       "      <td>5</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.017391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vucut_bolumu_iceriyor</th>\n",
       "      <td>6</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.865217</td>\n",
       "      <td>0.846739</td>\n",
       "      <td>0.790217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saglik_kavramlari_iceriyor</th>\n",
       "      <td>7</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.251087</td>\n",
       "      <td>0.247826</td>\n",
       "      <td>0.201087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hastalik_iceriyor</th>\n",
       "      <td>8</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.269565</td>\n",
       "      <td>0.227174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siyasi_rutbe_iceriyor</th>\n",
       "      <td>9</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.265217</td>\n",
       "      <td>0.265217</td>\n",
       "      <td>0.264130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siyasi_kavram_iceriyor</th>\n",
       "      <td>10</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.363043</td>\n",
       "      <td>0.363043</td>\n",
       "      <td>0.363043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siyasi_parti_iceriyor</th>\n",
       "      <td>11</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.082609</td>\n",
       "      <td>0.080435</td>\n",
       "      <td>0.079348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spor_kavramlar_iceriyor</th>\n",
       "      <td>12</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.320652</td>\n",
       "      <td>0.319565</td>\n",
       "      <td>0.313043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>takimlar_iceriyor</th>\n",
       "      <td>13</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.123913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spor_dallari_iceriyor</th>\n",
       "      <td>14</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.233696</td>\n",
       "      <td>0.231522</td>\n",
       "      <td>0.225000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             j Polarity  Coverage  Overlaps  Conflicts\n",
       "para_iceriyor                0      [1]  0.234783  0.234783   0.230435\n",
       "ekonomik_kavram_iceriyor     1      [1]  0.122826  0.121739   0.119565\n",
       "sayi_birimi_iceriyor         2      [1]  0.410870  0.409783   0.405435\n",
       "magazin_kavrami_iceriyor     3      [2]  0.547826  0.538043   0.528261\n",
       "magazin_meslegi_iceriyor     4      [2]  0.178261  0.175000   0.167391\n",
       "magazin_kisiler_iceriyor     5      [2]  0.021739  0.021739   0.017391\n",
       "vucut_bolumu_iceriyor        6      [3]  0.865217  0.846739   0.790217\n",
       "saglik_kavramlari_iceriyor   7      [3]  0.251087  0.247826   0.201087\n",
       "hastalik_iceriyor            8      [3]  0.271739  0.269565   0.227174\n",
       "siyasi_rutbe_iceriyor        9      [4]  0.265217  0.265217   0.264130\n",
       "siyasi_kavram_iceriyor      10      [4]  0.363043  0.363043   0.363043\n",
       "siyasi_parti_iceriyor       11      [4]  0.082609  0.080435   0.079348\n",
       "spor_kavramlar_iceriyor     12      [5]  0.320652  0.319565   0.313043\n",
       "takimlar_iceriyor           13      [5]  0.125000  0.125000   0.123913\n",
       "spor_dallari_iceriyor       14      [5]  0.233696  0.231522   0.225000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 15)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the labels from LFs into a single noise-aware probabilistic label per data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "\n",
    "majority_model = MajorityLabelVoter(6)\n",
    "preds_train = majority_model.predict(L=L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=6, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   76.1%\n",
      "Label Model Accuracy:     75.2%\n"
     ]
    }
   ],
   "source": [
    "Y_test = df_test.Sınıf.values\n",
    "\n",
    "majority_acc = majority_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "      \n",
    "label_model_acc = label_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **majority vote model** or more **sophisticated LabelModel** could in principle be used directly as a classifier if the outputs of our labeling functions were made available at test time. However, these models (i.e. these re-weighted combinations of our labeling function's votes) will *abstain on the data points that our labeling functions don't cover* (and additionally, may require slow or unavailable features to execute at test time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "probs_train = label_model.predict_proba(L=L_train)\n",
    "\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_train, y=probs_train, L=L_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 6)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "920"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 5))\n",
    "X_train = vectorizer.fit_transform(df_train_filtered.Haber.tolist())\n",
    "X_test = vectorizer.transform(df_test.Haber.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.utils import probs_to_preds\n",
    "\n",
    "preds_train_filtered = probs_to_preds(probs=probs_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(909,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 75.7%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_model = LogisticRegression(C=1e3, solver=\"liblinear\")\n",
    "sklearn_model.fit(X=X_train, y=preds_train_filtered)\n",
    "\n",
    "print(f\"Test Accuracy: {sklearn_model.score(X=X_test, y=Y_test) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  70.43478260869566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(X_train, preds_train_filtered)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(X_test)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \", accuracy_score(predictions_NB, Y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  68.69565217391305\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_train, preds_train_filtered)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(X_test)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM, Y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snorkel]",
   "language": "python",
   "name": "conda-env-snorkel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
