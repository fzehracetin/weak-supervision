{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Haber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>başbakan recep tayyip erdoğan, irak'ın bütünlü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>i̇stanbul üniversitesi (i̇ü) cerrahpaşa tıp fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>zayıflamak isteyenlere hep kalori hesabı yapıl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>vücudunun ve yüzünün hiçbir yerine bıçak değdi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>'ruhban okulu' formülü hazır  dışişleri bakanl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arzu yeniden botaşspor’da       bayanlar baske...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>milli takım cnn’de lider   ünlü haber kanalını...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>rumlara ab şoku       kıbrıs müzakerelerine ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>washi̇ uyandirdi   fenerbahçeli golcünün hasta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>taşlar yerine oturuyor       ak parti hükümeti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ankara - maliye bakanı kemal unakıtan, bankacı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>ulaştırma bakanlığı'nın, tek uçağı bulunan sag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tevfik lav imzayı attı      ankaragücü’nde mih...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>bartholomeos'u castro karşıladı          diş h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>kıbrıs'ta çözüm artık çok yakın       new york...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>filipinli yapışık ikizler ayrıldı   başlarında...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>sağlık bakanlığı temel sağlık hizmetleri genel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>baş ağrılarının nedenleri saymakla bitmez.başı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>papandreu, tedavi altında   yunanistan ana muh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>'gelin inceleyin'  erdoğan'la görüşen talabani...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Haber\n",
       "8   başbakan recep tayyip erdoğan, irak'ın bütünlü...\n",
       "71  i̇stanbul üniversitesi (i̇ü) cerrahpaşa tıp fa...\n",
       "89  zayıflamak isteyenlere hep kalori hesabı yapıl...\n",
       "28  vücudunun ve yüzünün hiçbir yerine bıçak değdi...\n",
       "63  'ruhban okulu' formülü hazır  dışişleri bakanl...\n",
       "0   arzu yeniden botaşspor’da       bayanlar baske...\n",
       "5   milli takım cnn’de lider   ünlü haber kanalını...\n",
       "50  rumlara ab şoku       kıbrıs müzakerelerine ab...\n",
       "82  washi̇ uyandirdi   fenerbahçeli golcünün hasta...\n",
       "4   taşlar yerine oturuyor       ak parti hükümeti...\n",
       "23  ankara - maliye bakanı kemal unakıtan, bankacı...\n",
       "65  ulaştırma bakanlığı'nın, tek uçağı bulunan sag...\n",
       "77  tevfik lav imzayı attı      ankaragücü’nde mih...\n",
       "60  bartholomeos'u castro karşıladı          diş h...\n",
       "24  kıbrıs'ta çözüm artık çok yakın       new york...\n",
       "42  filipinli yapışık ikizler ayrıldı   başlarında...\n",
       "88  sağlık bakanlığı temel sağlık hizmetleri genel...\n",
       "38  baş ağrılarının nedenleri saymakla bitmez.başı...\n",
       "56  papandreu, tedavi altında   yunanistan ana muh...\n",
       "76  'gelin inceleyin'  erdoğan'la görüşen talabani..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "news = []\n",
    "\n",
    "for directory in os.listdir(\"1150haber/raw_texts/\"):\n",
    "    for filename in os.listdir(\"1150haber/raw_texts/\" + directory):\n",
    "        f = open(\"1150haber/raw_texts/\" + directory + \"/\" + filename, \"r\", encoding=\"windows-1254\")\n",
    "        new = f.read().replace(\"\\n\", \" \")\n",
    "        new = new.lower()\n",
    "        news.append(new)\n",
    "        \n",
    "random.shuffle(news)\n",
    "print(len(news))\n",
    "\n",
    "data = {\"Haber\": news}\n",
    "df_train = pd.DataFrame(data)\n",
    "df_train[\"Haber\"] = df_train[\"Haber\"].apply(str)\n",
    "df_train.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Haber</th>\n",
       "      <th>Sınıf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efes turu kapti : 75-57   lacivert-beyazlılar ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sakin pes etme       fenerbahçe teknik direktö...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chp muhalefeti tatilde  muhalifler ihraç edile...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kartal’ın keyfi yerinde   beşiktaş, fenerbahçe...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gurbetçilerin tercihi \"o şarkılar\" albümü   ya...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>ssk’ya pahalı ilaç satarak devleti zarara uğra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>doğum kayıtları, internette   konya dr. faruk ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>abd: bizden iyi dostunuz yok  ankara milliyet ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>japan tobacco international (jti), geçen hafta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>baykal'ın derdi aday bulamamak       yerel seç...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Haber  Sınıf\n",
       "0    efes turu kapti : 75-57   lacivert-beyazlılar ...      5\n",
       "1    sakin pes etme       fenerbahçe teknik direktö...      5\n",
       "2    chp muhalefeti tatilde  muhalifler ihraç edile...      4\n",
       "3    kartal’ın keyfi yerinde   beşiktaş, fenerbahçe...      5\n",
       "4    gurbetçilerin tercihi \"o şarkılar\" albümü   ya...      2\n",
       "..                                                 ...    ...\n",
       "225  ssk’ya pahalı ilaç satarak devleti zarara uğra...      1\n",
       "226  doğum kayıtları, internette   konya dr. faruk ...      3\n",
       "227  abd: bizden iyi dostunuz yok  ankara milliyet ...      4\n",
       "228  japan tobacco international (jti), geçen hafta...      1\n",
       "229  baykal'ın derdi aday bulamamak       yerel seç...      4\n",
       "\n",
       "[230 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "news = []\n",
    "labels = []\n",
    "filenames = []\n",
    "i = 0\n",
    "\n",
    "for directory in os.listdir(\"1150haber/test/\"):\n",
    "    i += 1\n",
    "    for filename in os.listdir(\"1150haber/test/\" + directory):\n",
    "        f = open(\"1150haber/test/\" + directory + \"/\" + filename, \"r\", encoding=\"windows-1254\")\n",
    "        new = f.read().replace(\"\\n\", \" \")\n",
    "        new = new.lower()\n",
    "        news.append(new)\n",
    "        labels.append(i)\n",
    "        \n",
    "print(len(news))\n",
    "\n",
    "data = {\"Haber\": news, \"Sınıf\": labels}\n",
    "df_test = pd.DataFrame(data)\n",
    "df_test[\"Haber\"] = df_test[\"Haber\"].apply(str)\n",
    "df_test = df_test.sample(frac = 1).reset_index(drop=True)\n",
    "df_test.sample(230).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EKONOMI = 1\n",
    "MAGAZIN = 2\n",
    "SAGLIK = 3\n",
    "SIYASI = 4\n",
    "SPOR = 5\n",
    "BELIRSIZ = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ekonomi_kavramlar1 = [\"lira\", \"ticaret\", \"merkez bankası\", \"ssk\", \"kredi\", \"maliye\", \"tüketim\", \"faiz\"]\n",
    "ekonomi_kavramlar2 = [\"cari\", \"milyar\", \"milyon\", \"kurul\", \"tüketici\", \"dolar\",\"ekonomi\"]\n",
    "\n",
    "magazin_kavramlar1 = [\"manken\", \"konser\", \"eşi\", \"bodrum\", \"evlilik\"]\n",
    "magazin_kavramlar2 = [\"sevgili\", \"güzellik\", \"nişantaşı\", \"mayo\", \"podyum\"]\n",
    "\n",
    "saglik_kavramlar1 = [\"dr.\", \"sağlık\", \"koruyucu\", \"ilaç\", \"cilt\", \"kalsiyum\", \"fiziksel\", \"güneş\", \"hastalık\", \"hipertansiyon\"]\n",
    "saglik_kavramlar2 = [\"ultraviyole\", \"alerji\", \"yağ\", \"estetik\", \"tedavi\", \"kalp\", \"tansiyon\", \"boyun\", \"kalori\", \"vitamin\", \"göğüs\"]\n",
    "\n",
    "siyasi_kavramlar1 = [\"başkan\", \"dışişleri\", \"erdoğan\", \"avrupa\", \"abd\", \"pkk\", \"talabani\", \"almanya\", \"anayasa\", \"milletvekili\", \"müzakere\" ]\n",
    "siyasi_kavramlar2 = [\"cumhurbaşkanı\", \"büyükşehir\", \"fransa\", \"chp\", \"akp\", \"tbmm\", \"yolsuzluk\", \"mahkeme\" ]\n",
    "\n",
    "spor_kavramlar1 = [\"teknik\", \"futbol\", \"transfer\", \"fenerbahçe\", \"direktör\", \"futbolcu\", \"spor\", \"galatasaray\", \"sezon\"]\n",
    "spor_kavramlar2 = [\"maç\", \"takım\", \"beşiktaş\", \"terim\", \"trabzonspor\", \"şampiyon\", \"lig\", \"pota\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "import re\n",
    "\n",
    "@labeling_function()\n",
    "def ekonomik_kavram_iceriyor1(sample_new):\n",
    "    for ekonomik_kavram in ekonomi_kavramlar1:\n",
    "         if re.search(ekonomik_kavram, sample_new.Haber):\n",
    "            return EKONOMI\n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def ekonomik_kavram_iceriyor2(sample_new):\n",
    "    for sayi_birimi in ekonomi_kavramlar2:\n",
    "        if re.search(sayi_birimi, sample_new.Haber):\n",
    "            return EKONOMI \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def magazin_kavrami_iceriyor1(sample_new):\n",
    "    for magazin_kavrami in magazin_kavramlar1:\n",
    "        if re.search(magazin_kavrami, sample_new.Haber):\n",
    "            return MAGAZIN \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def magazin_kavrami_iceriyor2(sample_new):\n",
    "    for magazin_kisisi in magazin_kavramlar2:\n",
    "        if re.search(magazin_kisisi, sample_new.Haber):\n",
    "            return MAGAZIN \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def saglik_kavramlari_iceriyor1(sample_new):\n",
    "    for saglik_kavrami in saglik_kavramlar1:\n",
    "        if re.search(saglik_kavrami, sample_new.Haber):\n",
    "            return SAGLIK\n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def saglik_kavramlari_iceriyor2(sample_new):\n",
    "    for hastalik in saglik_kavramlar2:\n",
    "        if re.search(hastalik, sample_new.Haber):\n",
    "            return SAGLIK \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def siyasi_kavram_iceriyor1(sample_new):\n",
    "    for siyasi_kavram in siyasi_kavramlar1:\n",
    "        if re.search(siyasi_kavram, sample_new.Haber):\n",
    "            return SIYASI \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def siyasi_kavram_iceriyor2(sample_new):\n",
    "    for siyasi_parti in siyasi_kavramlar2:\n",
    "        if re.search(siyasi_parti, sample_new.Haber):\n",
    "            return SIYASI \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def spor_kavramlar_iceriyor1(sample_new):\n",
    "    for spor_kavrami in spor_kavramlar1:\n",
    "        if re.search(spor_kavrami, sample_new.Haber):\n",
    "            return SPOR \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def spor_kavramlar_iceriyor2(sample_new):\n",
    "    for takim in spor_kavramlar2:\n",
    "        if re.search(takim, sample_new.Haber):\n",
    "            return SPOR \n",
    "    return BELIRSIZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 920/920 [00:02<00:00, 351.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 230/230 [00:00<00:00, 337.45it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [ekonomik_kavram_iceriyor1, ekonomik_kavram_iceriyor2, magazin_kavrami_iceriyor1, magazin_kavrami_iceriyor2, saglik_kavramlari_iceriyor1, saglik_kavramlari_iceriyor2,\n",
    "siyasi_kavram_iceriyor1, siyasi_kavram_iceriyor2, spor_kavramlar_iceriyor1, spor_kavramlar_iceriyor2]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "L_test = applier.apply(df=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ekonomik_kavram_iceriyor1</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.201087</td>\n",
       "      <td>0.196739</td>\n",
       "      <td>0.178261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ekonomik_kavram_iceriyor2</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.372826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magazin_kavrami_iceriyor1</th>\n",
       "      <td>2</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.342391</td>\n",
       "      <td>0.322826</td>\n",
       "      <td>0.311957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magazin_kavrami_iceriyor2</th>\n",
       "      <td>3</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.078261</td>\n",
       "      <td>0.068478</td>\n",
       "      <td>0.057609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saglik_kavramlari_iceriyor1</th>\n",
       "      <td>4</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.378261</td>\n",
       "      <td>0.359783</td>\n",
       "      <td>0.334783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saglik_kavramlari_iceriyor2</th>\n",
       "      <td>5</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.201087</td>\n",
       "      <td>0.176087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siyasi_kavram_iceriyor1</th>\n",
       "      <td>6</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.517391</td>\n",
       "      <td>0.476087</td>\n",
       "      <td>0.436957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siyasi_kavram_iceriyor2</th>\n",
       "      <td>7</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.192391</td>\n",
       "      <td>0.153261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spor_kavramlar_iceriyor1</th>\n",
       "      <td>8</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.253261</td>\n",
       "      <td>0.248913</td>\n",
       "      <td>0.227174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spor_kavramlar_iceriyor2</th>\n",
       "      <td>9</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.239130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             j Polarity  Coverage  Overlaps  Conflicts\n",
       "ekonomik_kavram_iceriyor1    0      [1]  0.201087  0.196739   0.178261\n",
       "ekonomik_kavram_iceriyor2    1      [1]  0.408696  0.391304   0.372826\n",
       "magazin_kavrami_iceriyor1    2      [2]  0.342391  0.322826   0.311957\n",
       "magazin_kavrami_iceriyor2    3      [2]  0.078261  0.068478   0.057609\n",
       "saglik_kavramlari_iceriyor1  4      [3]  0.378261  0.359783   0.334783\n",
       "saglik_kavramlari_iceriyor2  5      [3]  0.217391  0.201087   0.176087\n",
       "siyasi_kavram_iceriyor1      6      [4]  0.517391  0.476087   0.436957\n",
       "siyasi_kavram_iceriyor2      7      [4]  0.195652  0.192391   0.153261\n",
       "spor_kavramlar_iceriyor1     8      [5]  0.253261  0.248913   0.227174\n",
       "spor_kavramlar_iceriyor2     9      [5]  0.271739  0.260870   0.239130"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "\n",
    "majority_model = MajorityLabelVoter(6)\n",
    "preds_train = majority_model.predict(L=L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=6, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   67.4%\n",
      "Label Model Accuracy:     67.8%\n"
     ]
    }
   ],
   "source": [
    "Y_test = df_test.Sınıf.values\n",
    "\n",
    "majority_acc = majority_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "      \n",
    "label_model_acc = label_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "probs_train = label_model.predict_proba(L=L_train)\n",
    "\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_train, y=probs_train, L=L_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 5))\n",
    "X_train = vectorizer.fit_transform(df_train_filtered.Haber.tolist())\n",
    "X_test = vectorizer.transform(df_test.Haber.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.utils import probs_to_preds\n",
    "\n",
    "preds_train_filtered = probs_to_preds(probs=probs_train_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 81.3%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_model = LogisticRegression(C=1e3, solver=\"liblinear\")\n",
    "sklearn_model.fit(X=X_train, y=preds_train_filtered)\n",
    "print(f\"Test Accuracy: {sklearn_model.score(X=X_test, y=Y_test) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  64.34782608695652\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(X_train, preds_train_filtered)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(X_test)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \", accuracy_score(predictions_NB, Y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  77.39130434782608\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_train, preds_train_filtered)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(X_test)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM, Y_test)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snorkel]",
   "language": "python",
   "name": "conda-env-snorkel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
