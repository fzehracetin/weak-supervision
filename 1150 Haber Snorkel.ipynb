{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Haber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>ankara trafik vakfı tarafından yayınlanan traf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>'yosma' ile bir hafta sonu         koç holding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>enflasyon sepetinden tornavida çıkıyor, ekmek ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>güvenlik konseyi kıbrıs'ta bölündü   bm güvenl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>hakan peker 'taşgibi'     peker'in albüm fotoğ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>bağırsak kanserini önlemede röntgen teknolojis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luce’ni̇n i̇syani   zago’nun pozisyon hatası y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>göz göre göre   terim’in inanılmaz kredisi gal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>milli takım cnn’de lider   ünlü haber kanalını...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>beş farklı masaldan esinlenilerek çekilen ‘anl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>the interpreter’ adlı filminin öpüşme sahneler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>yeni tartışma: sarhoşlar anayasası   erdoğan'ı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>'müzakereleri engellemeyiz'  diş haberler serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>komşuda fiyatlara olimpiyat zammı         yuna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>karasakal'la kıbrıs savası       chp, akp'ye k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>öğrenciler hem yök'ü hem akp'yi eleştirdi     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>bilinçsiz diyetle zayıflayanları bekleyen “ano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>sevil sabancı, babası sakıp sabancı'nın vefatı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>anti-kanserojen madde üreten bakteri bulundu  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>abdullah aydın, türkiye’nin göz sağlığı konusu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Haber\n",
       "826  ankara trafik vakfı tarafından yayınlanan traf...\n",
       "176  'yosma' ile bir hafta sonu         koç holding...\n",
       "823  enflasyon sepetinden tornavida çıkıyor, ekmek ...\n",
       "62   güvenlik konseyi kıbrıs'ta bölündü   bm güvenl...\n",
       "241  hakan peker 'taşgibi'     peker'in albüm fotoğ...\n",
       "505  bağırsak kanserini önlemede röntgen teknolojis...\n",
       "2    luce’ni̇n i̇syani   zago’nun pozisyon hatası y...\n",
       "695  göz göre göre   terim’in inanılmaz kredisi gal...\n",
       "221  milli takım cnn’de lider   ünlü haber kanalını...\n",
       "699  beş farklı masaldan esinlenilerek çekilen ‘anl...\n",
       "127  the interpreter’ adlı filminin öpüşme sahneler...\n",
       "477  yeni tartışma: sarhoşlar anayasası   erdoğan'ı...\n",
       "179  'müzakereleri engellemeyiz'  diş haberler serv...\n",
       "0    komşuda fiyatlara olimpiyat zammı         yuna...\n",
       "137  karasakal'la kıbrıs savası       chp, akp'ye k...\n",
       "256  öğrenciler hem yök'ü hem akp'yi eleştirdi     ...\n",
       "117  bilinçsiz diyetle zayıflayanları bekleyen “ano...\n",
       "397  sevil sabancı, babası sakıp sabancı'nın vefatı...\n",
       "183  anti-kanserojen madde üreten bakteri bulundu  ...\n",
       "589  abdullah aydın, türkiye’nin göz sağlığı konusu..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "news = []\n",
    "\n",
    "for directory in os.listdir(\"1150haber/raw_texts/\"):\n",
    "    for filename in os.listdir(\"1150haber/raw_texts/\" + directory):\n",
    "        f = open(\"1150haber/raw_texts/\" + directory + \"/\" + filename, \"r\", encoding=\"windows-1254\")\n",
    "        new = f.read().replace(\"\\n\", \" \")\n",
    "        new = new.lower()\n",
    "        news.append(new)\n",
    "        \n",
    "random.shuffle(news)\n",
    "print(len(news))\n",
    "\n",
    "data = {\"Haber\": news}\n",
    "df_train = pd.DataFrame(data)\n",
    "df_train[\"Haber\"] = df_train[\"Haber\"].apply(str)\n",
    "df_train.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Haber</th>\n",
       "      <th>Sınıf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chp'den kızılay için soru önergesi   chp i̇sta...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>çocuğuna \"eskilerini\" giydiriyor   ünlü oyuncu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google'da playboy tedirginliği  playboy'a veri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ankara üniversitesi tıp fakültesi farmakoloji ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cim-bom ateş hattında : 2-3   yeşilyurt önünde...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>[habersağlık-i̇stanbul] diyabet, kalp hastalık...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>alinur velidedeoğlu ile ayşe çavuşoğlu'nun ber...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>ümi̇tler’den tek yumruk : 1-0   ay-yıldızlı ek...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>artık helin'in de bir butiği olacak   hülya av...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>merkezde, üreme sağlığı konularına ağırlık ver...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Haber  Sınıf\n",
       "0    chp'den kızılay için soru önergesi   chp i̇sta...      3\n",
       "1    çocuğuna \"eskilerini\" giydiriyor   ünlü oyuncu...      2\n",
       "2    google'da playboy tedirginliği  playboy'a veri...      1\n",
       "3    ankara üniversitesi tıp fakültesi farmakoloji ...      3\n",
       "4    cim-bom ateş hattında : 2-3   yeşilyurt önünde...      5\n",
       "..                                                 ...    ...\n",
       "225  [habersağlık-i̇stanbul] diyabet, kalp hastalık...      3\n",
       "226  alinur velidedeoğlu ile ayşe çavuşoğlu'nun ber...      2\n",
       "227  ümi̇tler’den tek yumruk : 1-0   ay-yıldızlı ek...      5\n",
       "228  artık helin'in de bir butiği olacak   hülya av...      2\n",
       "229  merkezde, üreme sağlığı konularına ağırlık ver...      3\n",
       "\n",
       "[230 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "news = []\n",
    "labels = []\n",
    "filenames = []\n",
    "i = 0\n",
    "\n",
    "for directory in os.listdir(\"1150haber/test/\"):\n",
    "    i += 1\n",
    "    for filename in os.listdir(\"1150haber/test/\" + directory):\n",
    "        f = open(\"1150haber/test/\" + directory + \"/\" + filename, \"r\", encoding=\"windows-1254\")\n",
    "        new = f.read().replace(\"\\n\", \" \")\n",
    "        new = new.lower()\n",
    "        news.append(new)\n",
    "        labels.append(i)\n",
    "        \n",
    "print(len(news))\n",
    "\n",
    "data = {\"Haber\": news, \"Sınıf\": labels}\n",
    "df_test = pd.DataFrame(data)\n",
    "df_test[\"Haber\"] = df_test[\"Haber\"].apply(str)\n",
    "df_test = df_test.sample(frac = 1).reset_index(drop=True)\n",
    "df_test.sample(230).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background for labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = [\"lira\", \"dolar\", \"döviz\", \"faiz\"]\n",
    "ekonomi_kavramlar = [\"cari\", \"enflasyon\", \"merkez bankası\", \"imf\", \"kredi\", \"yatırım\"]\n",
    "sayi_birimleri = [\"milyon\", \"milyar\", \"bin\", \"trilyon\", \"katrilyon\"]\n",
    "\n",
    "magazin_kavramlar = [\"ünlü\", \"tatil\", \"bodrum\", \"konser\", \"sevgili\", \"yakışıklı\", \"aşk\"]\n",
    "magazin_meslekler = [\"manken\", \"oyuncu\", \"aktör\"]\n",
    "magazin_kisiler = [\"hülya avşar\", \"beren saat\", \"ajda pekkan\", \"demet akalın\", \"mehmet ali erbil\"]\n",
    "\n",
    "vucut_bolumleri = [\"kalp\", \"diş\", \"göz\", \"damar\", \"ağız\", \"cilt\", \"vücut\", \"yağ\"]\n",
    "saglik_kavramlar = [\"tedavi\", \"bilim\", \"ilaç\", \"teşhis\", \"hasta\", \"tıp\", \"ameliyat\", \"ssk\"]\n",
    "hastaliklar = [\"kanser\", \"şeker\", \"yağ\", \"hastalık\", \"doğum\", \"anne\", \"görme\"]\n",
    "\n",
    "siyasi_rutbeler = [\"genel başkanı\", \"milletvekili\", \"bakan\", \"başbakan\", \"cumhurbaşkanı\", \"dışişleri\"]\n",
    "siyasi_kavramlar = [\"abd\", \"erdoğan\", \"kılıçdaroğlu\", \"demirtaş\", \"bahçeli\", \"akşener\", \"avrupa\", \"büyükşehir\", \"anayasa\", \"abd\"]\n",
    "siyasi_partiler = [\"akp\", \"chp\", \"mhp\", \"hdp\"]\n",
    "\n",
    "spor_kavramlar = [\"teknik\", \"milli\", \"gol\", \"takım\", \"maç\", \"transfer\", \"forma\", \"uefa\", \"direktör\", \"terim\"]\n",
    "takimlar = [\"fenerbahçe\", \"galatasaray\", \"beşiktaş\", \"trabzonspor\", \"barcelona\", \"arjantin\", \"kocaelispor\"]\n",
    "dallar = [\"futbolcu\", \"kupa\", \"saha\", \"hakem\", \"lig\", \"rakip\", \"şampiyon\", \"deplasman\", \"futbol\", \"basketbol\", \"penaltı\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "EKONOMI = 1\n",
    "MAGAZIN = 2\n",
    "SAGLIK = 3\n",
    "SIYASI = 4\n",
    "SPOR = 5\n",
    "BELIRSIZ = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "import re\n",
    "\n",
    "@labeling_function()\n",
    "def para_iceriyor(sample_new):\n",
    "    for para_tipi in para:\n",
    "        if re.search(para_tipi, sample_new.Haber):\n",
    "            return EKONOMI \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def ekonomik_kavram_iceriyor(sample_new):\n",
    "    for ekonomik_kavram in ekonomi_kavramlar:\n",
    "         if re.search(ekonomik_kavram, sample_new.Haber):\n",
    "            return EKONOMI\n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def sayi_birimi_iceriyor(sample_new):\n",
    "    for sayi_birimi in sayi_birimleri:\n",
    "        if re.search(sayi_birimi, sample_new.Haber):\n",
    "            return EKONOMI \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def magazin_kavrami_iceriyor(sample_new):\n",
    "    for magazin_kavrami in magazin_kavramlar:\n",
    "        if re.search(magazin_kavrami, sample_new.Haber):\n",
    "            return MAGAZIN \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def magazin_meslegi_iceriyor(sample_new):\n",
    "    for magazin_meslegi in magazin_meslekler:\n",
    "        if re.search(magazin_meslegi, sample_new.Haber):\n",
    "            return MAGAZIN \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def magazin_kisiler_iceriyor(sample_new):\n",
    "    for magazin_kisisi in magazin_kisiler:\n",
    "        if re.search(magazin_kisisi, sample_new.Haber):\n",
    "            return MAGAZIN \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def vucut_bolumu_iceriyor(sample_new):\n",
    "    for vucut_bolumu in vucut_bolumleri:\n",
    "        if re.search(vucut_bolumu, sample_new.Haber):\n",
    "            return SAGLIK \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def saglik_kavramlari_iceriyor(sample_new):\n",
    "    for saglik_kavrami in saglik_kavramlar:\n",
    "        if re.search(saglik_kavrami, sample_new.Haber):\n",
    "            return SAGLIK\n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def hastalik_iceriyor(sample_new):\n",
    "    for hastalik in hastaliklar:\n",
    "        if re.search(hastalik, sample_new.Haber):\n",
    "            return SAGLIK \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def siyasi_rutbe_iceriyor(sample_new):\n",
    "    for siyasi_rutbe in siyasi_rutbeler:\n",
    "        if re.search(siyasi_rutbe, sample_new.Haber):\n",
    "            return SIYASI \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def siyasi_kavram_iceriyor(sample_new):\n",
    "    for siyasi_kavram in siyasi_kavramlar:\n",
    "        if re.search(siyasi_kavram, sample_new.Haber):\n",
    "            return SIYASI \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def siyasi_parti_iceriyor(sample_new):\n",
    "    for siyasi_parti in siyasi_partiler:\n",
    "        if re.search(siyasi_parti, sample_new.Haber):\n",
    "            return SIYASI \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def spor_kavramlar_iceriyor(sample_new):\n",
    "    for spor_kavrami in spor_kavramlar:\n",
    "        if re.search(spor_kavrami, sample_new.Haber):\n",
    "            return SPOR \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def takimlar_iceriyor(sample_new):\n",
    "    for takim in takimlar:\n",
    "        if re.search(takim, sample_new.Haber):\n",
    "            return SPOR \n",
    "    return BELIRSIZ\n",
    "\n",
    "@labeling_function()\n",
    "def spor_dallari_iceriyor(sample_new):\n",
    "    for spor_dali in dallar:\n",
    "        if re.search(spor_dali, sample_new.Haber):\n",
    "            return SPOR \n",
    "    return BELIRSIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 920/920 [00:01<00:00, 814.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [para_iceriyor, ekonomik_kavram_iceriyor, sayi_birimi_iceriyor, magazin_kavrami_iceriyor, magazin_meslegi_iceriyor, \n",
    "       magazin_kisiler_iceriyor, vucut_bolumu_iceriyor, saglik_kavramlari_iceriyor, hastalik_iceriyor, siyasi_rutbe_iceriyor, \n",
    "       siyasi_kavram_iceriyor, siyasi_parti_iceriyor, spor_kavramlar_iceriyor, takimlar_iceriyor, spor_dallari_iceriyor]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 230/230 [00:00<00:00, 676.30it/s]\n"
     ]
    }
   ],
   "source": [
    "L_test = applier.apply(df=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>para_iceriyor</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.234783</td>\n",
       "      <td>0.233696</td>\n",
       "      <td>0.220652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ekonomik_kavram_iceriyor</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.122826</td>\n",
       "      <td>0.121739</td>\n",
       "      <td>0.111957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sayi_birimi_iceriyor</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.410870</td>\n",
       "      <td>0.406522</td>\n",
       "      <td>0.390217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magazin_kavrami_iceriyor</th>\n",
       "      <td>3</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.547826</td>\n",
       "      <td>0.520652</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magazin_meslegi_iceriyor</th>\n",
       "      <td>4</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.178261</td>\n",
       "      <td>0.169565</td>\n",
       "      <td>0.155435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magazin_kisiler_iceriyor</th>\n",
       "      <td>5</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.013043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vucut_bolumu_iceriyor</th>\n",
       "      <td>6</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.393478</td>\n",
       "      <td>0.390217</td>\n",
       "      <td>0.352174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saglik_kavramlari_iceriyor</th>\n",
       "      <td>7</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.251087</td>\n",
       "      <td>0.238043</td>\n",
       "      <td>0.201087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hastalik_iceriyor</th>\n",
       "      <td>8</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.266304</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.222826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siyasi_rutbe_iceriyor</th>\n",
       "      <td>9</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.265217</td>\n",
       "      <td>0.263043</td>\n",
       "      <td>0.247826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siyasi_kavram_iceriyor</th>\n",
       "      <td>10</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.363043</td>\n",
       "      <td>0.360870</td>\n",
       "      <td>0.342391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siyasi_parti_iceriyor</th>\n",
       "      <td>11</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.082609</td>\n",
       "      <td>0.080435</td>\n",
       "      <td>0.071739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spor_kavramlar_iceriyor</th>\n",
       "      <td>12</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.320652</td>\n",
       "      <td>0.319565</td>\n",
       "      <td>0.298913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>takimlar_iceriyor</th>\n",
       "      <td>13</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.118478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spor_dallari_iceriyor</th>\n",
       "      <td>14</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.233696</td>\n",
       "      <td>0.229348</td>\n",
       "      <td>0.208696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             j Polarity  Coverage  Overlaps  Conflicts\n",
       "para_iceriyor                0      [1]  0.234783  0.233696   0.220652\n",
       "ekonomik_kavram_iceriyor     1      [1]  0.122826  0.121739   0.111957\n",
       "sayi_birimi_iceriyor         2      [1]  0.410870  0.406522   0.390217\n",
       "magazin_kavrami_iceriyor     3      [2]  0.547826  0.520652   0.500000\n",
       "magazin_meslegi_iceriyor     4      [2]  0.178261  0.169565   0.155435\n",
       "magazin_kisiler_iceriyor     5      [2]  0.021739  0.021739   0.013043\n",
       "vucut_bolumu_iceriyor        6      [3]  0.393478  0.390217   0.352174\n",
       "saglik_kavramlari_iceriyor   7      [3]  0.251087  0.238043   0.201087\n",
       "hastalik_iceriyor            8      [3]  0.266304  0.260870   0.222826\n",
       "siyasi_rutbe_iceriyor        9      [4]  0.265217  0.263043   0.247826\n",
       "siyasi_kavram_iceriyor      10      [4]  0.363043  0.360870   0.342391\n",
       "siyasi_parti_iceriyor       11      [4]  0.082609  0.080435   0.071739\n",
       "spor_kavramlar_iceriyor     12      [5]  0.320652  0.319565   0.298913\n",
       "takimlar_iceriyor           13      [5]  0.125000  0.125000   0.118478\n",
       "spor_dallari_iceriyor       14      [5]  0.233696  0.229348   0.208696"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 15)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the labels from LFs into a single noise-aware probabilistic label per data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "\n",
    "majority_model = MajorityLabelVoter(6)\n",
    "preds_train = majority_model.predict(L=L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=6, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   76.1%\n",
      "Label Model Accuracy:     72.6%\n"
     ]
    }
   ],
   "source": [
    "Y_test = df_test.Sınıf.values\n",
    "\n",
    "majority_acc = majority_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "      \n",
    "label_model_acc = label_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **majority vote model** or more **sophisticated LabelModel** could in principle be used directly as a classifier if the outputs of our labeling functions were made available at test time. However, these models (i.e. these re-weighted combinations of our labeling function's votes) will *abstain on the data points that our labeling functions don't cover* (and additionally, may require slow or unavailable features to execute at test time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "probs_train = label_model.predict_proba(L=L_train)\n",
    "\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_train, y=probs_train, L=L_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 5))\n",
    "X_train = vectorizer.fit_transform(df_train_filtered.Haber.tolist())\n",
    "X_test = vectorizer.transform(df_test.Haber.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.utils import probs_to_preds\n",
    "\n",
    "preds_train_filtered = probs_to_preds(probs=probs_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_model = LogisticRegression(C=1e3, solver=\"liblinear\")\n",
    "sklearn_model.fit(X=X_train, y=preds_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 74.8%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {sklearn_model.score(X=X_test, y=Y_test) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snorkel]",
   "language": "python",
   "name": "conda-env-snorkel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
